\section{Results}
\label{sec:results}

\import{.}{figure-table-best-score}

\subsection{Cost-benefit analysis of contextual embeddings}
\label{sec:cost-benefit}

\import{.}{figure-chart-score-time}

\todonum{Write this section.}

\subsection{Language-specificity of window-size effects}

Generally, I found that the scores obtained by both static- and contextual-embedding
models were maximised by a non-zero context-window size.
The influence of the window size is intuitive in the case of static embeddings.
Without a context window, the representations of a target word only differ between
expressions if the word is represented by different sub-word tokens in the different
expressions.
A similar argument applies to contextual embeddings, in that a target word may be
represented by multiple sub-word tokens.
For the additive composition operation, the scores against window size for each
language and model are given in
\cref{chart:score-window-static,chart:score-window-contextual,chart:score-window-pooled}.

% \import{.}{figure-table-best-window-size}
\import{.}{figure-chart-score-window}